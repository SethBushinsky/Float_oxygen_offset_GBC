{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Float BGC Bias Correction, parallel version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original version: Veronica Tamsitt (USF)\n",
    "\n",
    "Current version: Seth Bushinsky, Zachary Nachod (UH Manoa)\n",
    "\n",
    "Adapted from original MATLAB code written by Seth Bushinsky (UH)\n",
    "\n",
    "    Download and process GLODAP data\n",
    "    apply float bias corrections and calculate derivative variables (pH, TALK)\n",
    "    do float - glodap crossover comparison\n",
    "    do float - float crossover comparison\n",
    "\n",
    "Link to MATLAB LIAR/LIPHR code: https://github.com/BRCScienceProducts/LIRs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import glob, os\n",
    "import time\n",
    "from multiprocessing import Pool\n",
    "import functions.float_data_processing as fl\n",
    "import numpy as np\n",
    "import functions.argo_interp_and_crossover as aiac\n",
    "import functions.carbon_utils as carbon_utilities\n",
    "import PyCO2SYS as pyco2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in a user-created text file to point to local directories to avoid having to change this every time \n",
    "# we update code\n",
    "lines=[]\n",
    "with open('path_file.txt') as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "count = 0\n",
    "for line in lines:\n",
    "    count += 1\n",
    "    index = line.find(\"=\")\n",
    "    #print(f'line {count}: {line}')\n",
    "    #print(index)\n",
    "    #print(line[0:index])\n",
    "    line = line.rstrip()\n",
    "    if line[0:index].find(\"argo\")>=0:\n",
    "        argo_path=line[index+1:]\n",
    "    elif line[0:index].find(\"liar\")>=0:\n",
    "        liar_dir=line[index+1:]\n",
    "    elif line[0:index].find(\"matlab\")>=0:\n",
    "        matlab_dir=line[index+1:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User definted inputs\n",
    "\n",
    "adjustment = False # allows read in of outputs from previous crossover and apply them in a rough approximation of correction \n",
    "\n",
    "#pressure limits for interpolation of \n",
    "p_interp_min = 1450 #minimum pressure for float crossover comparison\n",
    "p_interp_max = 2000 #maximum pressure for float crossover comparison\n",
    "\n",
    "# p_interp_min = 500 #minimum pressure for float crossover comparison\n",
    "# p_interp_max = 2000 #maximum pressure for float crossover comparison\n",
    "# p_interp_min = 1 #minimum pressure for float crossover comparison\n",
    "# p_interp_max = 550 #maximum pressure for float crossover comparison\n",
    "#pressure levels to interpolate to, every 1db\n",
    "p_interp = np.arange(p_interp_min,p_interp_max+1)\n",
    "\n",
    "# select glodap pressure range for comparison\n",
    "# p_compare_min = 400\n",
    "# p_compare_max = 2100\n",
    "\n",
    "# p_compare_min = 1\n",
    "# p_compare_max = 500\n",
    "\n",
    "p_compare_min = 1400\n",
    "p_compare_max = 2100\n",
    "\n",
    "#max density difference to store crossover\n",
    "delta_dens = 0.005\n",
    "# delta_dens = 0.05\n",
    "\n",
    "#max spice difference to store crossover\n",
    "delta_spice = 0.005\n",
    "# delta_spice = 0.05\n",
    "\n",
    "# max pressure difference to store crossover\n",
    "delta_press = 100\n",
    "# delta_press = 25\n",
    "\n",
    "#crossover distance range\n",
    "# dist = 50\n",
    "dist = 100\n",
    "\n",
    "\n",
    "\n",
    "# choose whether to use ESPER or LIPHR for GLODAP crossover comparison\n",
    "# pH_alg = 'LIPHR'\n",
    "pH_alg = 'ESPER'\n",
    "print(pH_alg)\n",
    "\n",
    "# when making major changes, list version number here\n",
    "ver_n = '14' \n",
    "# v11 - fixing Data Mode issue\n",
    "# v2 - moving interpolated spice and density calculation to post-PSAL and TEMP interpolation\n",
    "# v3 - fixed PH_25C calculation for float data, fixed in situ pH comparison (I think)\n",
    "# v4 - added back in SI and NO3 to DIC calculation - makes a difference apparently (also changes which points have valid data)\n",
    "# v5 - trying to do near-surface comparisons as well \n",
    "# v6 - working on full depth comparison that I will then separate by depth \n",
    "# v7 - trying to move code to parallel computing \n",
    "# v8 - now can choose whether to use ESPER or LIPHR to calculate GLODAP pH values for comparison \n",
    "# v9 - adding correction calculation option for nitrate, pH, dic\n",
    "# v10 - adding pHCalcTF flag to ESPER calculation - this instructs ESPER to calculate pH for agreement with DIC/TA, not spec pH \n",
    "# v12 - changing pHCalcTF back to 0 (false) - consistent with MBARI's processing now \n",
    "# v13 - changing pH 25C comparison to be at 1500 db instead of in situ pressure\n",
    "# v14 - re-doing full depth crossover comparison\n",
    "run_str = str(dist) + 'km_' \\\n",
    "    + str(p_compare_min) + '_to_' + str(p_compare_max) + '_' + str(delta_press) + 'm_' + \\\n",
    "    str(delta_dens) + 'dens_' + str(delta_spice) + 'spice' + '_' + pH_alg + '_' + ver_n\n",
    "\n",
    "if not os.path.isdir(argo_path):\n",
    "    os.mkdir(argo_path)\n",
    "\n",
    "# Set the paths\n",
    "if adjustment is True:\n",
    "    print('Using adjusted path')\n",
    "    argo_path = argo_path + '../Corrected/Sprof/'\n",
    "\n",
    "output_dir = argo_path + '../output_' + run_str + '/'\n",
    "data_dir = 'data/'\n",
    "\n",
    "#check directories exist\n",
    "if not os.path.isdir(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "if not os.path.isdir('data'):\n",
    "    os.mkdir('data')\n",
    "\n",
    "# Check for a glodap_offsets_plots directory, create if it does not exist\n",
    "offset_dir = output_dir + 'glodap_offset_plots/'\n",
    "if not os.path.isdir(offset_dir):\n",
    "    os.mkdir(offset_dir)\n",
    "\n",
    "\n",
    "glodap_file_offsets_dir = output_dir + 'glodap_file_offsets_' + run_str + '/'\n",
    "\n",
    "if not os.path.isdir(glodap_file_offsets_dir):\n",
    "    os.mkdir(glodap_file_offsets_dir)\n",
    "\n",
    "argo_path_interpolated = argo_path+'../interpolated_for_crossovers_' + run_str + '/'\n",
    "if not os.path.isdir(argo_path_interpolated):\n",
    "    os.mkdir(argo_path_interpolated)\n",
    "\n",
    "#add derived float file directory within argo_path\n",
    "argo_path_derived = argo_path+'../derived_for_crossovers_' + run_str + '/'\n",
    "if not os.path.isdir(argo_path_derived):\n",
    "    os.mkdir(argo_path_derived)\n",
    "\n",
    "glodap_offsets_filename = 'glodap_offsets_' + run_str + '.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs that usually will not change:\n",
    "\n",
    "#variables to do crossovers\n",
    "var_list_plot = ['PRES_ADJUSTED','TEMP_ADJUSTED','PSAL_ADJUSTED','DOXY_ADJUSTED','NITRATE_ADJUSTED',\n",
    "                 'DIC','pH_25C_TOTAL_ADJUSTED','PH_IN_SITU_TOTAL_ADJUSTED','PDENS', 'pH_25C_T_P1500']\n",
    "\n",
    "qc_data_fields = ['TEMP_ADJUSTED', 'PSAL_ADJUSTED', 'DOXY_ADJUSTED', 'NITRATE_ADJUSTED', \n",
    "                  'PRES_ADJUSTED', 'PH_IN_SITU_TOTAL_ADJUSTED']\n",
    "\n",
    "bgc_data_fields = ['DOXY_ADJUSTED', 'NITRATE_ADJUSTED', 'PH_IN_SITU_TOTAL_ADJUSTED']\n",
    "\n",
    "#variables to save to derived file\n",
    "derived_list = ['TEMP_ADJUSTED', 'PSAL_ADJUSTED', 'DOXY_ADJUSTED', 'NITRATE_ADJUSTED', 'PH_IN_SITU_TOTAL_ADJUSTED',\n",
    "            'pH_25C_TOTAL_ADJUSTED', 'PDENS', 'spice', 'PRES_ADJUSTED', 'DIC','TALK_LIAR', 'pH_25C_T_P1500']\n",
    "\n",
    "# variables to do interpolation on - must be present here for crossovers to work\n",
    "interpolation_list = ['TEMP_ADJUSTED', 'PSAL_ADJUSTED', 'DOXY_ADJUSTED', 'NITRATE_ADJUSTED', 'PH_IN_SITU_TOTAL_ADJUSTED',\n",
    "            'pH_25C_TOTAL_ADJUSTED', 'PRES_ADJUSTED', 'DIC','TALK_LIAR', 'pH_25C_T_P1500']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download and process GLODAP data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdap = fl.get_glodap(data_dir, year = 2023)\n",
    "\n",
    "gdap.loc[gdap['G2longitude']<0., \"G2longitude\"] = gdap.G2longitude[gdap['G2longitude']<0.] + 360.\n",
    "# gdap.G2longitude[gdap.G2longitude < 0.] = gdap.G2longitude[gdap.G2longitude < 0.] + 360.\n",
    "#set flagged data to NaN (is this needed? or masked array better?)\n",
    "# flagvars = ['G2salinity','G2oxygen','G2nitrate','G2tco2','G2talk','G2phts25p0']\n",
    "flagvars = ['G2salinity','G2oxygen','G2nitrate','G2tco2','G2talk','G2phts25p0', 'G2phtsinsitutp', 'G2salinity']\n",
    "\n",
    "# no flags for temperature or pressure, set those to nan if = -9999.0\n",
    "gdap.loc[gdap['G2temperature']==-9999.0, \"G2temperature\"] = np.nan\n",
    "gdap.loc[gdap['G2pressure']==-9999.0, \"G2pressure\"] = np.nan\n",
    "\n",
    "for v in flagvars:\n",
    "    flag = v+'f'\n",
    "    naninds = gdap[flag]!=2\n",
    "    gdap.loc[naninds, v] = np.nan\n",
    "    # gdap[v][naninds] = np.nan\n",
    "\n",
    "# GLODAP derived variables: density, MLD and pH\n",
    "\n",
    "#calc potential density\n",
    "gdap['sigma0_calculated'] = carbon_utilities.sigma0(gdap.G2salinity.values,gdap.G2temperature.values,\n",
    "                                  gdap.G2longitude.values,gdap.G2latitude.values,gdap.G2pressure.values)\n",
    "\n",
    "\n",
    "#calculate spice\n",
    "gdap['spice'] = carbon_utilities.spiciness0(gdap.G2salinity.values,gdap.G2temperature.values,\n",
    "                                  gdap.G2longitude.values,gdap.G2latitude.values,gdap.G2pressure.values)\n",
    "\n",
    "\n",
    "#pH from LIPHR\n",
    "# calculate LIPHR pH at Glodap points below 1480 m and above 2020m (V: where does the depth restriction come in?)\n",
    "LIPHR_path = liar_dir\n",
    "Coordinates = np.stack((gdap.G2longitude.values.flatten(), \n",
    "                        gdap.G2latitude.values.flatten(), \n",
    "                        gdap.G2pressure.values.flatten()),\n",
    "                        axis=1)\n",
    "Measurements = np.stack((gdap.G2salinity.values.flatten(), \n",
    "                         gdap.G2temperature.values.flatten(), \n",
    "                         gdap.G2oxygen.values.flatten()),\n",
    "                         axis=1)\n",
    "\n",
    "\n",
    "if pH_alg=='LIPHR':           \n",
    "    MeasIDVec = [1, 7, 6]\n",
    "    results = carbon_utilities.LIPHR_matlab(LIPHR_path,\n",
    "                                        Coordinates.tolist(),\n",
    "                                        Measurements.tolist(),\n",
    "                                        MeasIDVec, \n",
    "                                        OAAdjustTF = False)            \n",
    "elif pH_alg=='ESPER':\n",
    "    MeasIDVec_ESPER = [1, 2, 6] # S, T, O2 - different numbering than v2 LIRs\n",
    "    Equations = 7 # for ESPER - asking to use equation w/ S, T, and O2 only \n",
    "    DesiredVariables = [3] # in situ pH on total scale \n",
    "\n",
    "    # calculate decimal_year for ESPER\n",
    "    da = gdap.datetime\n",
    "    decimal_year = da.dt.year + (da.dt.dayofyear - 1 + (da.dt.hour * 3600 + da.dt.minute * 60 + da.dt.second) / 86400) / (365 + da.dt.is_leap_year)\n",
    "    results = carbon_utilities.ESPER_mixed_matlab(LIPHR_path,\n",
    "                                                    DesiredVariables,\n",
    "                                                    Coordinates.tolist(),\n",
    "                                                    Measurements.tolist(),\n",
    "                                                    MeasIDVec_ESPER,\n",
    "                                                    Equations, \n",
    "                                                    decimal_year.values.tolist(), \n",
    "                                                    0, 0)\n",
    "gdap['pH_in_situ_total'] = results\n",
    "\n",
    "\n",
    "# gdap.pH_in_situ_total[np.isnan(gdap.G2phts25p0)] = np.nan\n",
    "gdap.loc[np.isnan(gdap.G2phts25p0), 'pH_in_situ_total'] = np.nan\n",
    "# gdap pH 25C \n",
    "\n",
    "\n",
    "results = pyco2.sys(\n",
    "    par1=2300, \n",
    "    par2=gdap.pH_in_situ_total,\n",
    "    par1_type=1,\n",
    "    par2_type=3,\n",
    "    temperature=gdap.G2temperature, \n",
    "    pressure=gdap.G2pressure, \n",
    "    salinity=gdap.G2salinity, \n",
    "    temperature_out=25., #fixed 25C temperature\n",
    "    pressure_out=1500., # fixed output pressure\n",
    "    opt_pH_scale = 1, #total\n",
    "    opt_k_carbonic=10, #Lueker et al. 2000\n",
    "    opt_k_bisulfate=1, # Dickson 1990 (Note, matlab co2sys combines KSO4 with TB. option 3 = KSO4 of Dickson & TB of Lee 2010)\n",
    "    opt_total_borate=2, # Lee et al. 2010\n",
    "    opt_k_fluoride=2, # Perez and Fraga 1987\n",
    "    opt_buffers_mode=1, # used to be \"buffers_mode='auto'\" but seems to have changed in versions of pyco2?\n",
    ")\n",
    "\n",
    "pH_25Cp1500 = results['pH_total_out']\n",
    "gdap['pH_25C_T_P1500'] = pH_25Cp1500\n",
    "\n",
    "\n",
    "# gdap.pH_25C_T_P1500[np.isnan(gdap.G2phts25p0)]=np.nan\n",
    "gdap.loc[np.isnan(gdap.G2phts25p0), 'pH_25C_T_P1500'] = np.nan\n",
    "\n",
    "gdap['pH_25C_TOTAL_ADJUSTED'] = carbon_utilities.co2sys_pH25C(2300.,gdap.pH_in_situ_total,gdap.G2temperature,\n",
    "                                                         gdap.G2salinity,gdap.G2pressure)\n",
    "#set pH to nan where there was no original pH data from GLODAP\n",
    "# gdap.pH_25C_TOTAL_ADJUSTED[np.isnan(gdap.G2phts25p0)]=np.nan\n",
    "gdap.loc[np.isnan(gdap.G2phts25p0), 'pH_25C_TOTAL_ADJUSTED'] = np.nan\n",
    "\n",
    "\n",
    "#rename GLODAP comparison variables to match argo\n",
    "gdap = gdap.rename(columns={'G2longitude':'LONGITUDE', 'G2latitude':'LATITUDE', 'G2pressure':'PRES_ADJUSTED',\n",
    "                            'G2temperature':'TEMP_ADJUSTED','G2salinity':'PSAL_ADJUSTED', \n",
    "                            'G2oxygen':'DOXY_ADJUSTED','G2nitrate':'NITRATE_ADJUSTED', 'G2tco2':'DIC', \n",
    "                            'G2talk':'TALK_LIAR', 'G2MLD':'MLD','G2o2sat':'o2sat', 'G2PTMP':'PTMP', \n",
    "                            'pH_in_situ_total':'PH_IN_SITU_TOTAL_ADJUSTED','sigma0_calculated':'PDENS'})\n",
    "\n",
    "gdap['obs_index']=gdap.reset_index().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(aiac)\n",
    "\n",
    "#toggle to plot offsets profile by profile\n",
    "plot_profile = 0\n",
    "\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "# 0: overwrites and runs all floats in the argo_path directory \n",
    "# 1: checks all argo files against floats with a derived file already created. Only runs floats if no derived file  \n",
    "# 2: runs specific floats listed below\n",
    "append_data = 0\n",
    "num_processes = 18  \n",
    "\n",
    "if 'argo_interp' in locals():\n",
    "    argo_interp.close()\n",
    "\n",
    "if 'argolist_run' in locals():\n",
    "    del argolist_run\n",
    "\n",
    "argolist = []\n",
    "\n",
    "for file in os.listdir(argo_path):\n",
    "    if file.endswith('Sprof.nc'):\n",
    "        argolist.append(file)\n",
    "argolist.sort()\n",
    "\n",
    "if append_data==1: # only run on files that do not have a derived file created yet\n",
    "    derivedfiles = []\n",
    "\n",
    "    for file in os.listdir(argo_path_derived):\n",
    "        if file.endswith('derived.nc'):\n",
    "            derivedfiles.append(file[0:7])\n",
    "    derivedfiles.sort()\n",
    "\n",
    "    if 'argolist_run' in locals():\n",
    "        del argolist_run\n",
    "\n",
    "    # list of all files not in the derived file list\n",
    "    argolist_run = []\n",
    "    print(len(argolist))\n",
    "    for file in argolist:\n",
    "        # print(file)\n",
    "        if file[0:7] not in derivedfiles:\n",
    "            argolist_run.append(file)\n",
    "    print(len(argolist_run))\n",
    "\n",
    "elif append_data==0:\n",
    "    argolist_run=argolist\n",
    "   \n",
    "else:\n",
    "    # argolist_run = ['5906547_Sprof.nc']\n",
    "    argolist_run = ['2902431_Sprof.nc']\n",
    "    # argolist_run = ['5906547_Sprof.nc',\n",
    "    #                     '5906548_Sprof.nc',\n",
    "    #                     '5906549_Sprof.nc', \n",
    "    #                     '5906550_Sprof.nc', \n",
    "    #                     '5906551_Sprof.nc', \n",
    "    #                     '5906552_Sprof.nc', \n",
    "    #                     '5906553_Sprof.nc',\n",
    "    #                     '5906562_Sprof.nc',\n",
    "    #                     '5906554_Sprof.nc',\n",
    "    #                     '5906561_Sprof.nc', \n",
    "    #                     '5906556_Sprof.nc',\n",
    "    #                     '5906558_Sprof.nc',\n",
    "    #                     '5906559_Sprof.nc',\n",
    "    #                     '5906557_Sprof.nc']\n",
    "\n",
    "#restrict glodap data to comparison pressure range\n",
    "gdap_p = gdap[(gdap.PRES_ADJUSTED.values>p_compare_min) & (gdap.PRES_ADJUSTED.values<p_compare_max)]\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    with Pool(processes=num_processes) as pool:\n",
    "        # Create a list of arguments for pool.starmap\n",
    "        argo_args = [(argo_path, liar_dir, argo_path_interpolated, argo_path_derived, file, qc_data_fields, bgc_data_fields, p_interp, derived_list, interpolation_list, adjustment) for file in argolist_run]\n",
    "        \n",
    "        # Use pool.starmap with the list of arguments\n",
    "        pool.starmap(aiac.argo_interp_profiles, argo_args)\n",
    "    \n",
    "    # print('here')\n",
    "    # only run glodap crossovers on floats that have an interpolated file \n",
    "    with Pool(processes=num_processes) as pool:\n",
    "        # Create a list of arguments for pool.starmap\n",
    "        argo_args = [(argo_path_interpolated, offset_dir, glodap_file_offsets_dir, file, dist, delta_dens, delta_spice, delta_press, \\\n",
    "                        gdap_p, p_interp, plot_profile, var_list_plot, p_compare_min, p_compare_max) for file in argolist_run]\n",
    "        \n",
    "        # Use pool.starmap with the list of arguments\n",
    "        pool.starmap(aiac.glodap_crossover_offsets, argo_args)\n",
    "\n",
    "# Now load in all individual offset files and concatenate into larger file\n",
    "crossover_list = []\n",
    "for file in os.listdir(glodap_file_offsets_dir):\n",
    "    if file.endswith('_offset.nc'):\n",
    "        crossover_list.append(file)\n",
    "# print(len(crossover_list))\n",
    "\n",
    "if 'glodap_offsets' in locals():\n",
    "       del glodap_offsets # deletes argo_interp in case this code is being run multiple times. \n",
    "\n",
    "for idx, gdap_offset_file in enumerate(crossover_list):\n",
    "    # print(idx)\n",
    "    # print(gdap_offset_file)\n",
    "    gdap_offset_n = xr.open_dataset(glodap_file_offsets_dir + gdap_offset_file)\n",
    "\n",
    "    if len(gdap_offset_n['N_CROSSOVERS'])>0:\n",
    "        if 'glodap_offsets' not in locals(): # modified to deal w/ situation where n==0 skipped defining argo_interp\n",
    "            glodap_offsets = gdap_offset_n\n",
    "        else:\n",
    "            glodap_offsets = xr.concat([glodap_offsets,gdap_offset_n],'N_CROSSOVERS')\n",
    "print(glodap_offsets)\n",
    "\n",
    "glodap_offsets.to_netcdf(output_dir+glodap_offsets_filename)\n",
    "\n",
    "print('Total number of glodap crossovers: ' + str(len(glodap_offsets.N_CROSSOVERS)))\n",
    "\n",
    "finish_time = time.perf_counter()\n",
    "print(\"Program finished in {} seconds - using multiprocessing\".format(finish_time - start_time))\n",
    "print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "from scipy import interpolate\n",
    "\n",
    "LIAR_path = liar_dir\n",
    "argo_file = '5906436_Sprof.nc'\n",
    "print('Processing float file '+ argo_file)\n",
    "with warnings.catch_warnings(): # seems to be an issue with xarray reading in the JULD_LOCATION values for some floats, doesn't seem to be impacting anything so I am suppressing these warnings\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    argo_n = xr.load_dataset(argo_path+argo_file)\n",
    "\n",
    "# print('here1.0')\n",
    "argo_n = argo_n.set_coords(('PRES_ADJUSTED','LATITUDE','LONGITUDE','JULD'))\n",
    "# print('here1.1')\n",
    "wmo_n = argo_n.PLATFORM_NUMBER.values.astype(int)[0]\n",
    "# wmo_list.append(wmo_n)\n",
    "\n",
    "nprof_n = argo_n.dims['N_PROF']\n",
    "\n",
    "p_interp_min = p_interp[0]\n",
    "p_interp_max = p_interp[-1]\n",
    "# print('here1.5')    \n",
    "\n",
    "#   set bad data and possibly bad data to NaN \n",
    "for q in qc_data_fields:      \n",
    "    if q in argo_n.keys():\n",
    "        qc_val = argo_n[q+'_QC'].values.astype('float')\n",
    "        \n",
    "        # for some reason the .where statement was not filtering out bad values. \n",
    "        # This code is now changing QC values of 0 (no qc), 3(probably bad), 4(bad), and 9 (missing value) to nans. \n",
    "        # interpolated values are set to nan next for BGC data\n",
    "        #argo_n[q].where(np.logical_and(qc_val<3.,qc_val>4.))\n",
    "        argo_n[q].values[np.logical_or(qc_val==4,qc_val==3)]=np.nan\n",
    "        argo_n[q].values[np.logical_or(qc_val==0,qc_val==9)]=np.nan\n",
    "        argo_n[q].values[np.logical_or(qc_val==5,qc_val==6)]=np.nan\n",
    "        argo_n[q].values[np.logical_or(qc_val==7,qc_val==8)]=np.nan\n",
    "\n",
    "        #check for any Inf values not included in QC flag and set to NaN\n",
    "        argo_n[q].values[np.isinf(argo_n[q]).values] = np.nan\n",
    "# print('here2')    \n",
    "# check for interpolated profile positions (under ice) and set all BGC data to nan\n",
    "qc_val = argo_n['POSITION_QC'].values.astype('float')\n",
    "for b in bgc_data_fields:\n",
    "    if b in argo_n.keys() and np.any(qc_val==8):\n",
    "        naninds = np.argwhere(qc_val==8)[:,0]\n",
    "        argo_n[b][naninds,:] = np.nan\n",
    "\n",
    "# interpolate temperature and salinity profile to fill in gaps that sometimes line up with pH measurements:\n",
    "for p in range(0, len(argo_n.N_PROF)):\n",
    "    press_p = argo_n['PRES_ADJUSTED'][p,:]\n",
    "    temp_p = argo_n['TEMP_ADJUSTED'][p,:]\n",
    "    sal_p = argo_n['PSAL_ADJUSTED'][p,:]\n",
    "\n",
    "    press_no_temp_nans = press_p[np.logical_and(~np.isnan(temp_p), ~np.isnan(press_p))]\n",
    "    temp_no_temp_nans = temp_p[np.logical_and(~np.isnan(temp_p), ~np.isnan(press_p))]\n",
    "\n",
    "    press_no_sal_nans = press_p[np.logical_and(~np.isnan(sal_p), ~np.isnan(press_p))]\n",
    "    sal_no_sal_nans = sal_p[np.logical_and(~np.isnan(sal_p), ~np.isnan(press_p))]\n",
    "\n",
    "    temp_interp_p = np.interp(press_p, press_no_temp_nans, temp_no_temp_nans)\n",
    "    sal_interp_p = np.interp(press_p, press_no_sal_nans, sal_no_sal_nans)\n",
    "\n",
    "    argo_n['TEMP_ADJUSTED'][p,:] = temp_interp_p\n",
    "    argo_n['PSAL_ADJUSTED'][p,:] = sal_interp_p\n",
    "\n",
    "\n",
    "# print('here2.1')    \n",
    "#Finding and removing all non-delayed mode data\n",
    "    # sometimes parameters are missing from profiles - \n",
    "    # need to loop through all profiles and check which parameters are present\n",
    "parameter_array = argo_n.STATION_PARAMETERS.values.astype(str)\n",
    "\n",
    "for idx in range(len(parameter_array)):\n",
    "    prof_parameters = parameter_array[idx]\n",
    "    # print(prof_parameters)\n",
    "    # print(idx)\n",
    "    # loop through each paramter in the profile \n",
    "    for var in prof_parameters:\n",
    "        var_str = var.strip()\n",
    "        if len(var_str)==0: # only proceed if the variable exists \n",
    "            continue\n",
    "        # print('here2.2a ' + var)\n",
    "\n",
    "        var_ind = [idx for idx, s in enumerate(prof_parameters) if s.strip()== var_str]\n",
    "        # print(var_ind)\n",
    "        # print('here2.2aa ' + var)\n",
    "\n",
    "        # get parameter data mode values for that profile / variable\n",
    "        var_data_mode = argo_n.PARAMETER_DATA_MODE[idx,var_ind].values\n",
    "        # print(var_data_mode)\n",
    "        # print('here2.2b ' + var)\n",
    "        decoded_arr = np.array([elem.decode() if isinstance(elem, bytes) else np.nan for elem in var_data_mode.flatten()])\n",
    "        # print(decoded_arr)\n",
    "        result = np.where(decoded_arr == 'D', False, True) # true whereever mode is not delayed\n",
    "        # print(result)\n",
    "        # print('here2.2c ' + var)\n",
    "\n",
    "        if result:\n",
    "            argo_n[var_str +'_ADJUSTED'][idx,:] = np.nan\n",
    "# print('here2.5')\n",
    "# we are currently processing floats that have no valid biogeochemical data. \n",
    "#Should check to see if data in key \n",
    "#original bgc parameters (O2, NO3, pH) is valid and skip the rest if not\n",
    "bgc_valid = 0\n",
    "for b in bgc_data_fields:\n",
    "    if b in argo_n.keys() and np.any(~np.isnan(argo_n[b])):\n",
    "        bgc_valid = bgc_valid+1\n",
    "if bgc_valid >=1:\n",
    "    print(argo_file + ' has valid BGC data')\n",
    "else:\n",
    "    print(argo_file + ' has no valid BGC data')\n",
    "    # return\n",
    "\n",
    "argo_n['PDENS'] = (['N_PROF','N_LEVELS'],np.empty(argo_n.PRES_ADJUSTED.shape)) #nprof x nlevel\n",
    "argo_n.PDENS[:] = np.nan\n",
    "argo_n['spice'] = (['N_PROF','N_LEVELS'],np.empty(argo_n.PRES_ADJUSTED.shape)) #nprof x nlevel\n",
    "argo_n.spice[:] = np.nan\n",
    "# print('here3')\n",
    "#initialise interpolated dataset for float\n",
    "nan_interp = np.empty((nprof_n,p_interp.shape[0]))\n",
    "nan_interp[:] = np.nan\n",
    "argo_interp_n = xr.Dataset()\n",
    "argo_interp_n['wmo'] = (['N_PROF'],np.repeat(wmo_n,nprof_n))\n",
    "argo_interp_n['profile'] = (['N_PROF'],argo_n.CYCLE_NUMBER.data) # added .data \n",
    "argo_interp_n['juld'] = (['N_PROF'],argo_n.JULD_LOCATION.data)\n",
    "#add lat -lons to Dataset\n",
    "argo_interp_n['LATITUDE']  = (['N_PROF'],argo_n.LATITUDE.data)\n",
    "argo_interp_n['LONGITUDE']  = (['N_PROF'],argo_n.LONGITUDE.data)\n",
    "argo_interp_n['num_var'] = (['N_PROF'],np.zeros((nprof_n))) # changed from np.empty to np.zeros to avoid filling array with random large numbers\n",
    "for v in derived_list: # all the variables that will be saved out in the derived and interpolated files\n",
    "    argo_interp_n[v] = (['N_PROF','N_LEVELS'],np.copy(nan_interp))\n",
    "\n",
    "# if reading in adjustment / offset data, load impacts and apply as appropriate\n",
    "if adjustment is True:\n",
    "    impact_n = xr.load_dataset(argo_path + argo_file[0:7] + '_impact.nc')\n",
    "    argo_n['DOXY_ADJUSTED'] = argo_n['DOXY_ADJUSTED'] - impact_n.mean_O2_offset\n",
    "    if 'NITRATE_ADJUSTED' in argo_n.keys():\n",
    "        argo_n['NITRATE_ADJUSTED'] = argo_n['NITRATE_ADJUSTED'] + impact_n.mean_nitrate_impact_change\n",
    "\n",
    "#check first if PH_IN_SITU_TOTAL_ADJUSTED exists\n",
    "if 'PH_IN_SITU_TOTAL_ADJUSTED' in argo_n.keys() and np.any(~np.isnan(argo_n.PH_IN_SITU_TOTAL_ADJUSTED)):\n",
    "    \n",
    "    print('Calculating TALK, DIC and pH 25C correction for float '+str(wmo_n))\n",
    "    \n",
    "    #initialise pH 25c and DIC variables - could do this only if float has pH\n",
    "    argo_n['TALK_LIAR'] = (['N_PROF','N_LEVELS'],np.empty(argo_n.PRES_ADJUSTED.shape)) #nprof x nlevel\n",
    "    argo_n.TALK_LIAR[:] = np.nan\n",
    "    argo_n['pH_25C_TOTAL_ADJUSTED'] = (['N_PROF','N_LEVELS'],np.empty(argo_n.PRES_ADJUSTED.shape)) #nprof x nlevel\n",
    "    argo_n.pH_25C_TOTAL_ADJUSTED[:] = np.nan\n",
    "    argo_n['DIC'] = (['N_PROF','N_LEVELS'],np.empty(argo_n.PRES_ADJUSTED.shape)) #nprof x nlevel\n",
    "    argo_n.DIC[:] = np.nan\n",
    "\n",
    "    ##### Calc float TALK       \n",
    "    #repeat lats, lons to match pressure shape\n",
    "    lons_rep = np.tile(argo_n.LONGITUDE.values,(argo_n.PRES_ADJUSTED.shape[1],1)).T\n",
    "    lats_rep = np.tile(argo_n.LATITUDE.values,(argo_n.PRES_ADJUSTED.shape[1],1)).T\n",
    "\n",
    "    #set Si and PO4 inputs\n",
    "    #if nitrate, then use redfield for Si and PO4?, otherwise set to 0    \n",
    "    if 'NITRATE_ADJUSTED' in argo_n.keys():\n",
    "        SI = argo_n.NITRATE_ADJUSTED*2.5\n",
    "        SI.where(~np.isnan(SI), 0)\n",
    "        PO4 = argo_n.NITRATE_ADJUSTED/16\n",
    "        PO4.where(~np.isnan(PO4),0)\n",
    "        Coordinates = np.stack((lons_rep.flatten(), \n",
    "                        lats_rep.flatten(), \n",
    "                        argo_n.PRES_ADJUSTED.values.flatten()),\n",
    "                        axis=1)\n",
    "        Measurements = np.stack((argo_n.PSAL_ADJUSTED.values.flatten(), \n",
    "                            argo_n.TEMP_ADJUSTED.values.flatten(), \n",
    "                            argo_n.NITRATE_ADJUSTED.values.flatten(), \n",
    "                            argo_n.DOXY_ADJUSTED.values.flatten()),\n",
    "                            axis=1)\n",
    "        MeasIDVec = [1, 7, 3, 6]\n",
    "\n",
    "    else:\n",
    "        SI = np.zeros((argo_n.PH_IN_SITU_TOTAL_ADJUSTED.shape))\n",
    "        PO4 = np.zeros((argo_n.PH_IN_SITU_TOTAL_ADJUSTED.shape))\n",
    "        Coordinates = np.stack((lons_rep.flatten(), \n",
    "                        lats_rep.flatten(), \n",
    "                        argo_n.PRES_ADJUSTED.values.flatten()),\n",
    "                        axis=1)\n",
    "        Measurements = np.stack((argo_n.PSAL_ADJUSTED.values.flatten(), \n",
    "                            argo_n.TEMP_ADJUSTED.values.flatten(),\n",
    "                            argo_n.DOXY_ADJUSTED.values.flatten()),\n",
    "                            axis=1)\n",
    "        MeasIDVec = [1, 7, 6]                            \n",
    "\n",
    "\n",
    "    results = carbon_utilities.LIAR_matlab(LIAR_path,\n",
    "                                            Coordinates.tolist(),\n",
    "                                            Measurements.tolist(),\n",
    "                                            MeasIDVec,\n",
    "                                            VerboseTF=False)                                  \n",
    "\n",
    "    argo_n['TALK_LIAR'] = (['N_PROF','N_LEVELS'],\n",
    "                            np.reshape(np.asarray(results),argo_n.PH_IN_SITU_TOTAL_ADJUSTED.shape))\n",
    "\n",
    "\n",
    "    # Keep DIC bc I might want it for crossover comparison\n",
    "    ##### Calculate float pH at 25C, DIC and apply bias corr\n",
    "    results = pyco2.sys(\n",
    "            par1=argo_n.TALK_LIAR, \n",
    "            par2=argo_n.PH_IN_SITU_TOTAL_ADJUSTED,\n",
    "            par1_type=1,\n",
    "            par2_type=3,\n",
    "            temperature=argo_n.TEMP_ADJUSTED, \n",
    "            pressure=argo_n.PRES_ADJUSTED, \n",
    "            salinity=argo_n.PSAL_ADJUSTED, \n",
    "            temperature_out=25.,#*np.ones(argo_n.PRES_ADJUSTED.shape), #fixed 25C temperature\n",
    "            pressure_out=1500., #argo_n.PRES_ADJUSTED, # fixed 1500 db output pressure\n",
    "            total_silicate=SI,\n",
    "            total_phosphate=PO4,\n",
    "            opt_pH_scale = 1, #total\n",
    "            opt_k_carbonic=10, #Lueker et al. 2000\n",
    "            opt_k_bisulfate=1, # Dickson 1990 (Note, matlab co2sys combines KSO4 with TB. option 3 = KSO4 of Dickson & TB of Lee 2010)\n",
    "            opt_total_borate=2, # Lee et al. 2010\n",
    "            opt_k_fluoride=2, # Perez and Fraga 1987\n",
    "            opt_buffers_mode=1,\n",
    "    )\n",
    "    argo_n['pH_25C_T_P1500'] = (['N_PROF','N_LEVELS'], results['pH_total_out'])\n",
    "    argo_n['pH_25C_TOTAL_ADJUSTED'] = (['N_PROF','N_LEVELS'],carbon_utilities.co2sys_pH25C(argo_n.TALK_LIAR,\n",
    "                                                argo_n.PH_IN_SITU_TOTAL_ADJUSTED,\n",
    "                                                argo_n.TEMP_ADJUSTED,\n",
    "                                                argo_n.PSAL_ADJUSTED,\n",
    "                                                argo_n.PRES_ADJUSTED))\n",
    "\n",
    "    # if applying adjustment to pH - apply it to pH 25C, then recalculate pH insitu, then calculate DIC\n",
    "    if adjustment is True:\n",
    "        argo_n['pH_25C_TOTAL_ADJUSTED'] = argo_n['pH_25C_TOTAL_ADJUSTED'] + impact_n.mean_pH_impact_change # note that I am not correcting the in situ pH\n",
    "\n",
    "        results = pyco2.sys(\n",
    "            par1=argo_n.TALK_LIAR, \n",
    "            par2=argo_n.pH_25C_TOTAL_ADJUSTED, # using the impact adjusted pH\n",
    "            par1_type=1,\n",
    "            par2_type=3,\n",
    "            temperature=25, \n",
    "            pressure=argo_n.PRES_ADJUSTED, \n",
    "            salinity=argo_n.PSAL_ADJUSTED, \n",
    "            temperature_out=argo_n.TEMP_ADJUSTED,#*np.ones(argo_n.PRES_ADJUSTED.shape), #fixed 25C temperature\n",
    "            pressure_out=argo_n.PRES_ADJUSTED,\n",
    "            total_silicate=SI,\n",
    "            total_phosphate=PO4,\n",
    "            opt_pH_scale = 1, #total\n",
    "            opt_k_carbonic=10, #Lueker et al. 2000\n",
    "            opt_k_bisulfate=1, # Dickson 1990 (Note, matlab co2sys combines KSO4 with TB. option 3 = KSO4 of Dickson & TB of Lee 2010)\n",
    "            opt_total_borate=2, # Lee et al. 2010\n",
    "            opt_k_fluoride=2, # Perez and Fraga 1987\n",
    "            opt_buffers_mode=1,\n",
    "            )\n",
    "        argo_n['DIC'] = (['N_PROF','N_LEVELS'],results['dic'])  \n",
    "    else: # otherwise, just save DIC with no adjustment \n",
    "        argo_n['DIC'] = (['N_PROF','N_LEVELS'],results['dic'])  \n",
    "        \n",
    "##### now calc potential density, save, and interpolate data for comparison\n",
    "for p in range(nprof_n):\n",
    "    #pressure for profile\n",
    "    p_prof = argo_n.PRES_ADJUSTED[p,:]\n",
    "    \n",
    "    # For interpolated data, shouldn't calculate pdens and spice and then interpolate - \n",
    "    # should interpolate psal and temp and then calculate spice and pdens\n",
    "    # Do both so that you are able to have PDENS and spice in the derived files too (do I need them?)\n",
    "    argo_n['PDENS'][p,:] = carbon_utilities.sigma0(argo_n.PSAL_ADJUSTED[p,:].values,\n",
    "                                                argo_n.TEMP_ADJUSTED[p,:].values,\n",
    "                                                argo_n.LONGITUDE[p].values,\n",
    "                                                argo_n.LATITUDE[p].values,\n",
    "                                                argo_n.PRES_ADJUSTED[p,:].values)\n",
    "    argo_n['spice'][p,:] = carbon_utilities.spiciness0(argo_n.PSAL_ADJUSTED[p,:].values,\n",
    "                                                argo_n.TEMP_ADJUSTED[p,:].values,\n",
    "                                                argo_n.LONGITUDE[p].values,\n",
    "                                                argo_n.LATITUDE[p].values,\n",
    "                                                argo_n.PRES_ADJUSTED[p,:].values)\n",
    "\n",
    "    #for each profile get pressure values > p_interp_min db\n",
    "    p100 = p_prof[p_prof>p_interp_min].values\n",
    "        \n",
    "    #if only 1 value of pressure or if there is not valid profile data down to p-max, continue loop\n",
    "    if (len(p100) <= 1) or (np.nanmax(p100)<p_interp_min):\n",
    "        continue\n",
    "    \n",
    "    # # check for the presence of large gaps in the float profile data - can figure out how to deal with them once you know their prevalence \n",
    "    # if max(np.diff(p100))>125:\n",
    "    #     print(np.diff(p100))\n",
    "    #     data_out = p100.reshape(-1,1)\n",
    "    #     df = pd.DataFrame(data_out, columns = ['Pressure prior to interpolation'])\n",
    "    #     df.to_csv(argo_path_interpolated + str(wmo_n) + '_' + str(p) + '.csv', index=False)\n",
    "\n",
    "    #find which crossover variables exist in main float file\n",
    "    var_list_n = []\n",
    "    for vname in interpolation_list:\n",
    "        if (vname in argo_n.keys()) and (np.any(~np.isnan(argo_n[vname]))):\n",
    "            var_list_n.append(vname)\n",
    "            \n",
    "    argo_interp_n['num_var'][p] = len(var_list_n) \n",
    "    \n",
    "    for var in var_list_n:\n",
    "        var100 = argo_n[var][p,p_prof>p_interp_min]\n",
    "\n",
    "        #if there are non-unique pressure values, \n",
    "        #then grab only unique pressure values and matching data points\n",
    "        if len(p100)>len(np.unique(p100)):\n",
    "            p100u,unique_inds = np.unique(p100, return_index=True)\n",
    "            var100u = var100[unique_inds]\n",
    "        else:\n",
    "            p100u = p100\n",
    "            var100u = var100\n",
    "            \n",
    "        #interpolate 1d profile data onto p_interp levels \n",
    "        # use valid var data from p_interp_min to p_interp_max OR maximum valid pressure \n",
    "        #(greater than minimum comparison pressure)\n",
    "\n",
    "        if len(p100u[~np.isnan(var100u.values)])>1 and \\\n",
    "            (np.nanmax(p100u[~np.isnan(var100u.values)])>p_interp_min) and \\\n",
    "            (np.nanmin(p100u[~np.isnan(var100u.values)])<p_interp_max):\n",
    "            \n",
    "            #interpolation function\n",
    "            f = interpolate.interp1d(p100u[~np.isnan(var100u.values)],var100u[~np.isnan(var100u.values)])\n",
    "            \n",
    "            #check if non-NaN data does not extend down to p_interp_max\n",
    "            if np.logical_and((p100u[~np.isnan(var100u.values)][-1]<p_interp_max),\n",
    "                                (p100u[~np.isnan(var100u.values)][0]>p_interp_min)):\n",
    "                pmin_ind = np.argwhere(p_interp>p100u[~np.isnan(var100u.values)][0])[0][0]\n",
    "                pmax_ind = np.argwhere(p_interp>p100u[~np.isnan(var100u.values)][-1])[0][0]\n",
    "                #if  p100u[~np.isnan(var100u)][0]>p_interp_min:                   \n",
    "                var_interp_p = f(p_interp[pmin_ind:pmax_ind])\n",
    "                #assign interpolated variables to array \n",
    "                argo_interp_n[var][p,pmin_ind:pmax_ind] = var_interp_p\n",
    "                \n",
    "            elif p100u[~np.isnan(var100u.values)][-1]<p_interp_max:\n",
    "                pmax_ind = np.argwhere(p_interp>p100u[~np.isnan(var100u.values)][-1])[0][0]\n",
    "                var_interp_p = f(p_interp[:pmax_ind])\n",
    "                #assign interpolated variables to array \n",
    "                argo_interp_n[var][p,:pmax_ind] = var_interp_p\n",
    "                    \n",
    "            elif p100u[~np.isnan(var100u.values)][0]>p_interp_min:\n",
    "                pmin_ind = np.argwhere(p_interp>p100u[~np.isnan(var100u.values)][0])[0][0]\n",
    "                var_interp_p = f(p_interp[pmin_ind:])\n",
    "                #assign interpolated variables to array \n",
    "                argo_interp_n[var][p,pmin_ind:] = var_interp_p\n",
    "                \n",
    "            else:\n",
    "                var_interp_p = f(p_interp)\n",
    "                #assign interpolated variables to array \n",
    "                argo_interp_n[var][p,:] = var_interp_p\n",
    "        \n",
    "            # check for gaps in the original data greater than 125 m\n",
    "            gap_index= (np.diff(p100u)>125)\n",
    "\n",
    "            # if any values of gap_index are true, loop through and set values of interpolated data that are between value of large gaps to nan \n",
    "            if any(gap_index):\n",
    "                # temp_var = argo_interp_n[var][p,:]\n",
    "                # data_out = temp_var.values.reshape(-1,1)\n",
    "                # combined_data = np.hstack((p_interp.reshape(-1, 1), data_out))\n",
    "                # df = pd.DataFrame(combined_data, columns = ['Pressure', 'Oxygen'])\n",
    "                # df.to_csv(argo_path_interpolated + str(wmo_n) + '_' + str(p) + var + '.csv', index=False)\n",
    "\n",
    "                # print(argo_interp_n[var][p,:])\n",
    "                for idx, gi in enumerate(gap_index):\n",
    "                    if gi:\n",
    "                        # print(p100u[idx])\n",
    "                        # print(p100u[idx+1])\n",
    "                        argo_interp_n[var][p,np.logical_and(p_interp>p100u[idx],p_interp<p100u[idx+1])] = np.nan\n",
    "                # temp_var = argo_interp_n[var][p,:]\n",
    "                # data_out = temp_var.values.reshape(-1,1)\n",
    "                # combined_data = np.hstack((p_interp.reshape(-1, 1), data_out))\n",
    "                # df = pd.DataFrame(combined_data, columns = ['Pressure', 'Oxygen'])\n",
    "                # df.to_csv(argo_path_interpolated + str(wmo_n) + '_' + str(p) + var + '_after_removal.csv', index=False)\n",
    "\n",
    "#             else: \n",
    "            # print('profile data not deep enough to interpolate ' + str(p) + ' ' +  var)\n",
    "            #                       str(np.nanmax(p100u[~np.isnan(var100u.values)])))\n",
    "            # print('values greater than min ' + str(var100u[p100u>p_interp_min].values))\n",
    "\n",
    "# loop through profiles again to calculate PDENS and spice for interpolated dataset\n",
    "for p in range(nprof_n):\n",
    "    #pressure for profile\n",
    "    p_prof = argo_interp_n.PRES_ADJUSTED[p,:]\n",
    "\n",
    "    # For interpolated data, shouldn't calculate pdens and spice and then interpolate - \n",
    "    # should interpolate psal and temp and then calculate spice and pdens\n",
    "    # Do both so that you are able to have PDENS and spice in the derived files too (do I need them?)\n",
    "    argo_interp_n['PDENS'][p,:] = carbon_utilities.sigma0(argo_interp_n.PSAL_ADJUSTED[p,:].values,\n",
    "                                                argo_interp_n.TEMP_ADJUSTED[p,:].values,\n",
    "                                                argo_interp_n.LONGITUDE[p].values,\n",
    "                                                argo_interp_n.LATITUDE[p].values,\n",
    "                                                argo_interp_n.PRES_ADJUSTED[p,:].values)\n",
    "    argo_interp_n['spice'][p,:] = carbon_utilities.spiciness0(argo_interp_n.PSAL_ADJUSTED[p,:].values,\n",
    "                                                argo_interp_n.TEMP_ADJUSTED[p,:].values,\n",
    "                                                argo_interp_n.LONGITUDE[p].values,\n",
    "                                                    argo_interp_n.LATITUDE[p].values,\n",
    "                                                    argo_interp_n.PRES_ADJUSTED[p,:].values)\n",
    "    \n",
    "#create new dataset with relevant crossover variables only\n",
    "argo_n_derived = xr.Dataset()\n",
    "argo_n_derived['wmo'] = wmo_n\n",
    "argo_n_derived['CYCLE_NUMBER'] = (['N_PROF'],argo_n.CYCLE_NUMBER.values)\n",
    "argo_n_derived['LONGITUDE'] = (['N_PROF'],argo_n.LONGITUDE.values)\n",
    "argo_n_derived['LATITUDE'] = (['N_PROF'],argo_n.LATITUDE.values)\n",
    "argo_n_derived['JULD_LOCATION'] = (['N_PROF'],argo_n.JULD_LOCATION.values)\n",
    "for var in derived_list:\n",
    "    if var in argo_n.keys():\n",
    "        argo_n_derived[var] = (['N_PROF','N_LEVELS'],argo_n[var].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "argo_n_derived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(argo_n.N_PROF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=0\n",
    "\n",
    "press_p = argo_n['PRES_ADJUSTED'][p,:]\n",
    "temp_p = argo_n['TEMP_ADJUSTED'][p,:]\n",
    "sal_p = argo_n['PSAL_ADJUSTED'][p,:]\n",
    "\n",
    "press_no_temp_nans = press_p[np.logical_and(~np.isnan(temp_p), ~np.isnan(press_p))]\n",
    "temp_no_temp_nans = temp_p[np.logical_and(~np.isnan(temp_p), ~np.isnan(press_p))]\n",
    "\n",
    "press_no_sal_nans = press_p[np.logical_and(~np.isnan(sal_p), ~np.isnan(press_p))]\n",
    "sal_no_sal_nans = sal_p[np.logical_and(~np.isnan(sal_p), ~np.isnan(press_p))]\n",
    "\n",
    "temp_interp_p = np.interp(press_p, press_no_temp_nans, temp_no_temp_nans)\n",
    "sal_interp_p = np.interp(press_p, press_no_sal_nans, sal_no_sal_nans)\n",
    "\n",
    "# argo_n['TEMP_ADJUSTED'][p,:] = temp_interp_p\n",
    "# argo_n['PSAL_ADJUSTED'][p,:] = sal_interp_p\n",
    "# argo_n['TEMP_ADJUSTED'][p,:] = temp_interp_p\n",
    "# argo_n['TEMP_ADJUSTED'][p,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "l = 2\n",
    "plt.plot(argo_n['PH_IN_SITU_TOTAL_ADJUSTED'][2,:].values, argo_n['PRES_ADJUSTED'][p,:], 'x-')\n",
    "plt.plot(argo_n['TEMP_ADJUSTED'][p,:].values, argo_n['PRES_ADJUSTED'][p,:], 'x-')\n",
    "plt.plot(temp_interp_p, argo_n['PRES_ADJUSTED'][p,:], 'r--')\n",
    "\n",
    "\n",
    "plt.plot(argo_n['PSAL_ADJUSTED'][p,:].values, argo_n['PRES_ADJUSTED'][p,:], 'x-')\n",
    "plt.plot(sal_interp_p, argo_n['PRES_ADJUSTED'][p,:], 'x-')\n",
    "\n",
    "plt.ylim([0, 2000])\n",
    "plt.grid('on')\n",
    "# print(argo_n['TEMP_ADJUSTED'][2,l])\n",
    "# print(argo_n['PSAL_ADJUSTED'][2,l])\n",
    "# print(argo_n['PRES_ADJUSTED'][2,l])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_lims = [400, 470]\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "plt.pcolor(argo_n['PH_IN_SITU_TOTAL_ADJUSTED'])\n",
    "\n",
    "plt.colorbar()\n",
    "plt.subplot(2,2,4)\n",
    "plt.pcolor(argo_n['DIC'])\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pyco2.sys(\n",
    "        par1=argo_n.TALK_LIAR, \n",
    "        par2= argo_n.PH_IN_SITU_TOTAL_ADJUSTED,\n",
    "        par1_type=1,\n",
    "        par2_type=3,\n",
    "        temperature=argo_n.TEMP_ADJUSTED, \n",
    "        pressure=argo_n.PRES_ADJUSTED, \n",
    "        salinity=argo_n.PSAL_ADJUSTED, \n",
    "        temperature_out=25., #fixed 25C temperature\n",
    "        pressure_out=argo_n.PRES_ADJUSTED,\n",
    "        opt_pH_scale = 1, #total\n",
    "        opt_k_carbonic=10, #Lueker et al. 2000\n",
    "        opt_k_bisulfate=1, # Dickson 1990 (Note, matlab co2sys combines KSO4 with TB. option 3 = KSO4 of Dickson & TB of Lee 2010)\n",
    "        opt_total_borate=2, # Lee et al. 2010\n",
    "        opt_k_fluoride=2, # Perez and Fraga 1987\n",
    "        opt_buffers_mode=1, # used to be \"buffers_mode='auto'\" but seems to have changed in versions of pyco2?\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.keys()\n",
    "results['pH_total_out']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "float_oxygen_offset_impacts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
